{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget -O /kaggle/working/dataset.zip \"https://my.microsoftpersonalcontent.com/personal/802fb67c5dc88f59/_layouts/15/download.aspx?UniqueId=5dc88f59-b67c-202f-8080-f72e00000000&Translate=false&tempauth=v1e.eyJzaXRlaWQiOiJmNmNlZWYyYi1jNzQ2LTQxZjUtOWQ5MC1mOWQzZmM3N2MxODMiLCJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvbXkubWljcm9zb2Z0cGVyc29uYWxjb250ZW50LmNvbUA5MTg4MDQwZC02YzY3LTRjNWItYjExMi0zNmEzMDRiNjZkYWQiLCJleHAiOiIxNzMxMjc3NTQ1In0.E_mXbyPcs-EyrGMRBGJ3pyrWdsWOqcN4-h4bI9ASxkXG6AeX9nQx_IPOcJi78udKu5ZQtT3fnP9MT2J0ZLau-uB4iq4_UOTDiN2mROjAk3vTaGArh8_ZjT8viUZKJSloaDsMJCdx7V4xOMvoJCpxm3tXY0hNmcJQQ3s8B4aWW-tGi97gWNl582imIRGcmdXPNBDQJrD6BCQ6ZwVFeKli4qkWKK8iJuwN7xGsfSDAdaUGQSZFGdp3PhctY2h9o4vTmP88BVnzhIMGmGe7UYTJwzZnGllQ_3_80Fmco5f8xyTaryVIajmFmcrsuOuXNrnWcIKdeoD7uppZeUIAI2U9ijdUvXBuIZIbtf4LkWuOM9c5XRgAkG8ndGEIM2Qz5vsZZsQ9HZKvP8a-OVAGHkx9p0PBhl2V_k5lGMGYN4ojyXRQSSwqUUSr1PoI8JIwFBlY52n__55yzR3QhpUZVMUAUIGz7tTkeGuGGT2NcA1eQBacL55ftapugsqymBAxdc0DL8i84eh8dRiMFyGW_x6UQA.kG9R6Qe9KUoiEfK6nH_YkCNi4QMcLrtL27nOvwKuD3g&ApiVersion=2.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:23:08.800684Z","iopub.execute_input":"2024-11-10T22:23:08.801096Z","iopub.status.idle":"2024-11-10T22:24:04.680250Z","shell.execute_reply.started":"2024-11-10T22:23:08.801050Z","shell.execute_reply":"2024-11-10T22:24:04.679348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Define paths\ninput_zip_path = '/kaggle/working/dataset.zip'  # Update this path if needed\noutput_folder = '/kaggle/working/dataset'\n\n# Create the output directory if it doesnâ€™t exist\nos.makedirs(output_folder, exist_ok=True)\n\n# Unzip the dataset\nwith zipfile.ZipFile(input_zip_path, 'r') as zip_ref:\n    zip_ref.extractall(output_folder)\n\nprint(\"Dataset unzipped successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:24:45.414414Z","iopub.execute_input":"2024-11-10T22:24:45.415213Z","iopub.status.idle":"2024-11-10T22:25:01.711162Z","shell.execute_reply.started":"2024-11-10T22:24:45.415172Z","shell.execute_reply":"2024-11-10T22:25:01.710235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:31:48.162256Z","iopub.execute_input":"2024-11-10T22:31:48.163152Z","iopub.status.idle":"2024-11-10T22:31:48.168129Z","shell.execute_reply.started":"2024-11-10T22:31:48.163110Z","shell.execute_reply":"2024-11-10T22:31:48.167060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport os\n\n# Define a function to normalize image data\ndef normalize_images(images):\n    return images / 255.0  # Normalize RGB values to [0, 1]\n\n# Define a function to standardize fMRI data\ndef standardize_fmri(fmri_data):\n    mean = np.mean(fmri_data, axis=0)\n    std = np.std(fmri_data, axis=0)\n    return (fmri_data - mean) / std  # Standardize to mean 0 and std 1\n\n# Main function to preprocess data\ndef preprocess_and_save(subject_num, raw_data_dir, preprocessed_data_dir):\n    # Load image data\n    image_data = np.load(os.path.join(raw_data_dir, 'images_256.npz'))\n    train_images = image_data['train_images']\n    test_images = image_data['test_images']\n\n    # Normalize images\n    train_images_normalized = normalize_images(train_images)\n    test_images_normalized = normalize_images(test_images)\n\n    # Load fMRI data for the subject\n    subject_data = np.load(os.path.join(raw_data_dir, f'sbj_{subject_num}.npz'))\n    train_fmri = subject_data['arr_0']\n    test_fmri = subject_data['arr_2']\n\n    # Standardize fMRI data\n    train_fmri_standardized = standardize_fmri(train_fmri)\n    test_fmri_standardized = standardize_fmri(test_fmri)\n\n    # Save the preprocessed data as .npz files in the preprocessed data directory\n    np.savez(os.path.join(preprocessed_data_dir, f'preprocessed_data_subject_{subject_num}_train.npz'),\n             images=train_images_normalized, fmri=train_fmri_standardized)\n    np.savez(os.path.join(preprocessed_data_dir, f'preprocessed_data_subject_{subject_num}_test.npz'),\n             images=test_images_normalized, fmri=test_fmri_standardized)\n\n    print(f\"Preprocessed data for Subject {subject_num} saved as .npz files.\")\n\n# Set paths for Kaggle\nraw_data_dir = '/kaggle/working/dataset/data/Kamitani/npz'\npreprocessed_data_dir = '/kaggle/working/preprocessed'\n\n# Ensure the output directory exists\nos.makedirs(preprocessed_data_dir, exist_ok=True)\n\n# Preprocess and save data for each subject\nfor subject_num in range(1, 6):\n    preprocess_and_save(subject_num, raw_data_dir, preprocessed_data_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:28:09.844913Z","iopub.execute_input":"2024-11-10T22:28:09.845691Z","iopub.status.idle":"2024-11-10T22:28:40.810831Z","shell.execute_reply.started":"2024-11-10T22:28:09.845649Z","shell.execute_reply":"2024-11-10T22:28:40.809606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\n# Set device to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define dataset and model as before\nclass FMRIImageDataset(Dataset):\n    def __init__(self, npz_file):\n        data = np.load(npz_file)\n        self.images = data['images']\n        self.fmri = data['fmri']\n       \n    def __len__(self):\n        return len(self.images)\n       \n    def __getitem__(self, idx):\n        image = torch.tensor(self.images[idx], dtype=torch.float32)\n        fmri = torch.tensor(self.fmri[idx], dtype=torch.float32)\n        return fmri, image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:29:09.557230Z","iopub.execute_input":"2024-11-10T22:29:09.558202Z","iopub.status.idle":"2024-11-10T22:29:12.602364Z","shell.execute_reply.started":"2024-11-10T22:29:09.558150Z","shell.execute_reply":"2024-11-10T22:29:12.601552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generator Network with reduced layer sizes\nclass Generator(nn.Module):\n    def __init__(self, fmri_size, image_size):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.Linear(fmri_size, 256),  # Reduced layer size\n            nn.ReLU(),\n            nn.Linear(256, 512),       # Reduced layer size\n            nn.ReLU(),\n            nn.Linear(512, 1024),      # Reduced layer size\n            nn.ReLU(),\n            nn.Linear(1024, image_size),\n            nn.Tanh()  # Output range [-1, 1]\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\n# Discriminator Network with reduced layer sizes\nclass Discriminator(nn.Module):\n    def __init__(self, image_size):\n        super(Discriminator, self).__init__()\n        self.network = nn.Sequential(\n            nn.Linear(image_size, 512),       # Reduced layer size\n            nn.LeakyReLU(0.2),\n            nn.Linear(512, 256),              # Reduced layer size\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 128),              # Reduced layer size\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:36:17.271364Z","iopub.execute_input":"2024-11-10T22:36:17.271791Z","iopub.status.idle":"2024-11-10T22:36:17.281483Z","shell.execute_reply.started":"2024-11-10T22:36:17.271748Z","shell.execute_reply":"2024-11-10T22:36:17.280672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up device and parallel processing\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator = Generator(fmri_size=4466, image_size=256 * 256 * 3).to(device)\ndiscriminator = Discriminator(image_size=256 * 256 * 3).to(device)\n\nif torch.cuda.device_count() > 1:\n    generator = nn.DataParallel(generator)\n    discriminator = nn.DataParallel(discriminator)\n\n# Optimizers and loss function\ncriterion = nn.BCEWithLogitsLoss()\noptimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\nscaler = GradScaler()\n\n# Load preprocessed dataset\ntrain_dataset = FMRIImageDataset('/kaggle/working/preprocessed/preprocessed_data_subject_1_train.npz')\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:36:37.828525Z","iopub.execute_input":"2024-11-10T22:36:37.828893Z","iopub.status.idle":"2024-11-10T22:36:43.207707Z","shell.execute_reply.started":"2024-11-10T22:36:37.828860Z","shell.execute_reply":"2024-11-10T22:36:43.206915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torch.amp import autocast, GradScaler\n\n# Environment setting to reduce memory fragmentation\nimport os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# Hyperparameters\nfmri_size = 4466\nimage_size = 256 * 256 * 3\nbatch_size = 2  # Reduced to fit memory constraints\nnum_epochs = 10\nlearning_rate = 0.0002\naccumulation_steps = 4\n\n# Initialize models, loss function, and optimizers\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ngenerator = Generator(fmri_size=fmri_size, image_size=image_size).to(device)\ndiscriminator = Discriminator(image_size=image_size).to(device)\n\nif torch.cuda.device_count() > 1:\n    generator = nn.DataParallel(generator)\n    discriminator = nn.DataParallel(discriminator)\n\n# Optimizers and loss function\ncriterion = nn.BCEWithLogitsLoss()\noptimizer_g = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\noptimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\nscaler = GradScaler()\n\n# Load dataset\ntrain_dataset = FMRIImageDataset('/kaggle/working/preprocessed/preprocessed_data_subject_1_train.npz')\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Training loop with gradient accumulation and mixed precision\nfor epoch in range(num_epochs):\n    for i, (fmri, real_images) in enumerate(train_loader):\n        fmri = fmri.view(fmri.size(0), -1).to(device)\n        real_images = real_images.view(real_images.size(0), -1).to(device)\n        real_labels = torch.ones(fmri.size(0), 1).to(device)\n        fake_labels = torch.zeros(fmri.size(0), 1).to(device)\n\n        # Train Discriminator\n        with autocast('cuda'):\n            outputs = discriminator(real_images)\n            d_loss_real = criterion(outputs, real_labels)\n\n            fake_images = generator(fmri)\n            outputs = discriminator(fake_images.detach())\n            d_loss_fake = criterion(outputs, fake_labels)\n\n            d_loss = (d_loss_real + d_loss_fake) / accumulation_steps\n\n        optimizer_d.zero_grad()\n        scaler.scale(d_loss).backward()\n        if (i + 1) % accumulation_steps == 0:\n            scaler.step(optimizer_d)\n            scaler.update()\n\n        # Train Generator\n        with autocast('cuda'):\n            fake_images = generator(fmri)\n            outputs = discriminator(fake_images)\n            g_loss = criterion(outputs, real_labels) / accumulation_steps\n\n        optimizer_g.zero_grad()\n        scaler.scale(g_loss).backward()\n        if (i + 1) % accumulation_steps == 0:\n            scaler.step(optimizer_g)\n            scaler.update()\n\n        # Clear cache\n        torch.cuda.empty_cache()\n\n        # Monitor losses and scores\n        if (i + 1) % 100 == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], \"\n                  f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T22:36:54.548853Z","iopub.execute_input":"2024-11-10T22:36:54.549231Z","iopub.status.idle":"2024-11-10T23:29:47.020213Z","shell.execute_reply.started":"2024-11-10T22:36:54.549196Z","shell.execute_reply":"2024-11-10T23:29:47.019277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(generator.module.state_dict() if isinstance(generator, nn.DataParallel) else generator.state_dict(),\n           '/kaggle/working/generator_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T23:31:08.536731Z","iopub.execute_input":"2024-11-10T23:31:08.537419Z","iopub.status.idle":"2024-11-10T23:31:10.073765Z","shell.execute_reply.started":"2024-11-10T23:31:08.537377Z","shell.execute_reply":"2024-11-10T23:31:10.072972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_and_visualize(generator, test_loader, device):\n    generator.eval()\n    with torch.no_grad():\n        for fmri, original_images in test_loader:\n            fmri = fmri.view(fmri.size(0), -1).to(device)\n            generated_images = generator(fmri).cpu().view(-1, 256, 256, 3).numpy()\n            original_images = original_images.cpu().view(-1, 256, 256, 3).numpy()\n\n            generated_images = (generated_images + 1) / 2\n            original_images = (original_images + 1) / 2\n\n            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n            axes[0].imshow(original_images[0])\n            axes[0].set_title(\"Original Image\")\n            axes[0].axis(\"off\")\n\n            axes[1].imshow(generated_images[0])\n            axes[1].set_title(\"Generated Image\")\n            axes[1].axis(\"off\")\n            \n            plt.show()\n            break\n\ntest_loader = DataLoader(FMRIImageDataset('/kaggle/working/preprocessed/preprocessed_data_subject_1_test.npz'), batch_size=1)\ngenerate_and_visualize(generator, test_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T23:32:00.744837Z","iopub.execute_input":"2024-11-10T23:32:00.745212Z","iopub.status.idle":"2024-11-10T23:32:01.263149Z","shell.execute_reply.started":"2024-11-10T23:32:00.745178Z","shell.execute_reply":"2024-11-10T23:32:01.262282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}